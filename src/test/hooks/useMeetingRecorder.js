import { useState, useRef, useCallback, useEffect } from 'react';
import RecordRTC from 'recordrtc';
import { getRecordUrl } from '../../services/meetingApi';

export const useMeetingRecorder = (
  socket,
  roomId,
  stream,
  handleRecordingComplete
) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isRecordingDisabled, setIsRecordingDisabled] = useState(false);
  const [recordingUserId, setRecordingUserId] = useState(null);
  const recorderRef = useRef(null);
  const displayStreamRef = useRef(null);
  const audioContextRef = useRef(null);

  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);

  // Xá»­ lÃ½ khi cÃ³ ngÆ°á»i báº¯t Ä‘áº§u record
  useEffect(() => {
    if (!socket) return;

    const handleRecordStarted = ({ userId }) => {
      console.log(`Recording started by user: ${userId}`);
      setRecordingUserId(userId);
      if (userId !== socket.id) {
        setIsRecordingDisabled(true);
      }
    };

    const handleRecordStopped = ({ userId }) => {
      console.log(`Recording stopped by user: ${userId}`);
      setRecordingUserId(null);
      setIsRecordingDisabled(false);
    };

    socket.on('recordStarted', handleRecordStarted);
    socket.on('recordStopped', handleRecordStopped);

    return () => {
      socket.off('recordStarted', handleRecordStarted);
      socket.off('recordStopped', handleRecordStopped);
    };
  }, [socket]);

  // Cleanup function Ä‘á»ƒ Ä‘áº£m báº£o resources Ä‘Æ°á»£c giáº£i phÃ³ng Ä‘Ãºng
  const cleanupResources = useCallback(() => {
    console.log('ðŸ§¹ Cleaning up recording resources...');

    // Stop recorder
    if (recorderRef.current) {
      try {
        if (recorderRef.current.state === 'recording') {
          recorderRef.current.stopRecording();
        }
        recorderRef.current.destroy();
      } catch (e) {
        console.warn('Error destroying recorder:', e);
      }
      recorderRef.current = null;
    }

    // Close audio context
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      try {
        audioContextRef.current.close();
      } catch (e) {
        console.warn('Error closing audio context:', e);
      }
      audioContextRef.current = null;
    }

    // Stop display stream
    if (displayStreamRef.current) {
      displayStreamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log(`Stopped track: ${track.kind}`);
      });
      displayStreamRef.current = null;
    }

    console.log('âœ… Cleanup complete');
  }, []);
  // Dá»«ng recording
  const stopRecording = useCallback(() => {
    if (!recorderRef.current || !isRecording) {
      console.log('No active recording to stop');
      return;
    }

    console.log('ðŸ›‘ Stopping recording...');

    recorderRef.current.stopRecording(async () => {
      const blob = recorderRef.current.getBlob();

      console.log('âœ… Recording blob created:', {
        size: blob.size,
        type: blob.type,
      });

      const timestamp = new Date()
        .toISOString()
        .slice(0, 19)
        .replace(/:/g, '-')
        .replace('T', '_');

      // Táº¡o File object tá»« blob Ä‘á»ƒ upload
      const videoFile = new File([blob], `meeting_${timestamp}.webm`, {
        type: 'video/webm',
      });

      // ---- Báº®T Äáº¦U LOGIC UPLOAD ----
      setIsUploading(true);
      setUploadProgress(0);

      try {
        console.log('ðŸ“¤ Uploading video file...');
        setUploadProgress(30); // MÃ´ phá»ng tiáº¿n Ä‘á»™

        // 1. Gá»i API Ä‘á»ƒ upload vÃ  láº¥y URL
        // Giáº£ Ä‘á»‹nh response.data lÃ  URL string hoáº·c object { url: '...' }
        const response = await getRecordUrl(videoFile);

        setUploadProgress(70); // MÃ´ phá»ng tiáº¿n Ä‘á»™

        // TrÃ­ch xuáº¥t URL. TÃ¹y chá»‰nh náº¿u API tráº£ vá» cáº¥u trÃºc khÃ¡c
        const videoUrl = response.message ;

        if (!videoUrl || typeof videoUrl !== 'string') {
          throw new Error('KhÃ´ng nháº­n Ä‘Æ°á»£c URL video há»£p lá»‡ tá»« server');
        }

        console.log('âœ… Video uploaded, URL:', videoUrl);

        // 2. Gá»i callback tá»« MeetingRoomTest Ä‘á»ƒ nÃ³ gá»i updateMeeting
        if (handleRecordingComplete) {
          await handleRecordingComplete(videoUrl);
        }

        setUploadProgress(100); // HoÃ n táº¥t
      } catch (error) {
        console.error('âŒ Video upload or meeting update failed:', error);
        alert(
          'Lá»—i: KhÃ´ng thá»ƒ táº£i video lÃªn hoáº·c cáº­p nháº­t meeting. Vui lÃ²ng thá»­ láº¡i.'
        );
        setUploadProgress(0); // Reset náº¿u lá»—i
      } finally {
        setIsUploading(false); // áº¨n modal
      }
      // ---- Káº¾T THÃšC LOGIC UPLOAD ----

      // Cleanup resources
      cleanupResources();

      setIsRecording(false);

      if (socket && roomId) {
        socket.emit('requestStopRecord', roomId);
      }

      console.log('âœ… Recording stopped and process finished');
    });
  }, [isRecording, socket, roomId, cleanupResources, handleRecordingComplete]);

  // Báº¯t Ä‘áº§u recording
  const startRecording = useCallback(async () => {
    if (!socket || !roomId) {
      console.error('Missing socket or roomId');
      return;
    }

    // Cleanup trÆ°á»›c khi báº¯t Ä‘áº§u recording má»›i
    cleanupResources();

    socket.emit('requestStartRecord', roomId, async response => {
      if (!response.success) {
        alert(response.message || 'KhÃ´ng thá»ƒ báº¯t Ä‘áº§u ghi.');
        return;
      }

      try {
        console.log('ðŸŽ¬ Starting recording process...');

        // YÃªu cáº§u user chá»n mÃ n hÃ¬nh Ä‘á»ƒ record
        const displayStream = await navigator.mediaDevices.getDisplayMedia({
          video: {
            cursor: 'always',
            displaySurface: 'browser',
            frameRate: { ideal: 30, max: 30 },
          },
          audio: true, // Báº­t audio tá»« tab
          preferCurrentTab: true,
        });

        console.log('âœ… Display stream obtained:', {
          videoTracks: displayStream.getVideoTracks().length,
          audioTracks: displayStream.getAudioTracks().length,
        });

        displayStreamRef.current = displayStream;

        // Láº¯ng nghe khi user dá»«ng share tá»« browser
        displayStream.getVideoTracks()[0].onended = () => {
          console.log('User stopped screen sharing from browser UI');
          stopRecording();
        };

        // Táº¡o AudioContext má»›i
        audioContextRef.current = new AudioContext();
        const audioContext = audioContextRef.current;
        const dest = audioContext.createMediaStreamDestination();

        let hasAudio = false;

        // 1. Audio tá»« tab Ä‘Æ°á»£c share (system audio)
        const displayAudioTracks = displayStream.getAudioTracks();
        if (displayAudioTracks.length > 0) {
          try {
            const tabAudioStream = new MediaStream([displayAudioTracks[0]]);
            const source = audioContext.createMediaStreamSource(tabAudioStream);
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 1.0; // Volume 100%
            source.connect(gainNode);
            gainNode.connect(dest);
            hasAudio = true;
            console.log('âœ… Tab audio connected');
          } catch (e) {
            console.warn('Failed to connect tab audio:', e);
          }
        }

        // 2. Audio tá»« microphone
        if (stream) {
          const micAudioTracks = stream.getAudioTracks();
          if (micAudioTracks.length > 0) {
            try {
              const micStream = new MediaStream([micAudioTracks[0]]);
              const micSource = audioContext.createMediaStreamSource(micStream);
              const micGainNode = audioContext.createGain();
              micGainNode.gain.value = 1.0; // Volume 100%
              micSource.connect(micGainNode);
              micGainNode.connect(dest);
              hasAudio = true;
              console.log('âœ… Microphone audio connected');
            } catch (e) {
              console.warn('Failed to connect mic audio:', e);
            }
          }
        }

        // Táº¡o stream cuá»‘i cÃ¹ng
        const finalStream = new MediaStream();

        // Add video track
        const videoTrack = displayStream.getVideoTracks()[0];
        finalStream.addTrack(videoTrack);
        console.log('âœ… Video track added:', videoTrack.getSettings());

        // Add mixed audio track
        if (hasAudio && dest.stream.getAudioTracks().length > 0) {
          const audioTrack = dest.stream.getAudioTracks()[0];
          finalStream.addTrack(audioTrack);
          console.log('âœ… Audio track added:', audioTrack.getSettings());
        } else {
          console.warn('âš ï¸ No audio tracks available');
        }

        // Äá»£i má»™t chÃºt Ä‘á»ƒ stream á»•n Ä‘á»‹nh
        await new Promise(resolve => setTimeout(resolve, 500));

        // Khá»Ÿi táº¡o RecordRTC vá»›i config tá»‘i Æ°u
        const recorderOptions = {
          type: 'video',
          mimeType: 'video/webm;codecs=vp9,opus',
          videoBitsPerSecond: 2500000, // 2.5 Mbps
          audioBitsPerSecond: 128000,
          frameRate: 30,
          // Quan trá»ng: Ä‘áº£m báº£o RecordRTC chá» stream sáºµn sÃ ng
          initCallback: function () {
            console.log('RecordRTC initialized');
          },
        };

        // Fallback mimeType náº¿u vp9 khÃ´ng Ä‘Æ°á»£c há»— trá»£
        if (!MediaRecorder.isTypeSupported(recorderOptions.mimeType)) {
          recorderOptions.mimeType = 'video/webm;codecs=vp8,opus';
          console.log('Fallback to vp8');
        }

        recorderRef.current = new RecordRTC(finalStream, recorderOptions);

        // Báº¯t Ä‘áº§u recording
        recorderRef.current.startRecording();
        setIsRecording(true);

        console.log('âœ… Recording started successfully');
        console.log('Stream info:', {
          videoTracks: finalStream.getVideoTracks().length,
          audioTracks: finalStream.getAudioTracks().length,
          videoEnabled: finalStream.getVideoTracks()[0]?.enabled,
          audioEnabled: finalStream.getAudioTracks()[0]?.enabled,
        });
      } catch (err) {
        console.error('âŒ Recording error:', err);

        cleanupResources();

        if (err.name === 'NotAllowedError') {
          alert('Báº¡n cáº§n cho phÃ©p chia sáº» mÃ n hÃ¬nh Ä‘á»ƒ ghi meeting.');
        } else if (err.name === 'NotFoundError') {
          alert('KhÃ´ng tÃ¬m tháº¥y nguá»“n mÃ n hÃ¬nh Ä‘á»ƒ ghi.');
        } else {
          alert('Lá»—i khi báº¯t Ä‘áº§u ghi: ' + err.message);
        }

        socket.emit('requestStopRecord', roomId);
      }
    });
  }, [socket, roomId, cleanupResources, stream, stopRecording]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (isRecording) {
        console.log('Component unmounting, stopping recording...');
        cleanupResources();
        if (socket && roomId) {
          socket.emit('requestStopRecord', roomId);
        }
      }
    };
  }, [isRecording, socket, roomId, cleanupResources]);

  return {
    isRecording,
    isRecordingDisabled,
    recordingUserId,
    startRecording,
    stopRecording,
    isUploading,
    uploadProgress,
  };
};
